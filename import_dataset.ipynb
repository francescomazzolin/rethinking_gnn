{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing packages"
      ],
      "metadata": {
        "id": "7GBYQS6456P-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The packages specified in the paper's GitHub repository are:\n",
        "\n",
        "pytorch 1.9.0\n",
        "\n",
        "dgl 0.8.1\n",
        "\n",
        "sympy\n",
        "\n",
        "argparse\n",
        "\n",
        "scikit-learn\n",
        "\n",
        "PyTorch 1.9.0 requires an older version of Python to be installed, therefore we install Python 3.8"
      ],
      "metadata": {
        "id": "nTQRCBXq6Fxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3.8 python3.8-dev python3-pip -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeAytet_hEeg",
        "outputId": "da80e398-7cab-49a5-ace1-5e05cd292e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3-setuptools python3-wheel python3.8-minimal\n",
            "Suggested packages:\n",
            "  python-setuptools-doc python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3-pip python3-setuptools python3-wheel python3.8 python3.8-dev python3.8-minimal\n",
            "0 upgraded, 12 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 13.5 MB of archives.\n",
            "After this operation, 53.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.5 [1,306 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8 amd64 3.8.20-1+jammy1 [1,798 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-dev amd64 3.8.20-1+jammy1 [4,389 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-dev amd64 3.8.20-1+jammy1 [500 kB]\n",
            "Fetched 13.5 MB in 25s (537 kB/s)\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 123635 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../01-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../02-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../03-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../04-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8:amd64.\n",
            "Preparing to unpack .../05-libpython3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8-dev:amd64.\n",
            "Preparing to unpack .../06-libpython3.8-dev_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../07-python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../08-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../09-python3-pip_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../10-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-dev.\n",
            "Preparing to unpack .../11-python3.8-dev_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-dev (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-dev (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing PyTorch 1.9.0 gave many problems, we increased the version until there was one that did not give installation problem and allowed the script to work without hitches."
      ],
      "metadata": {
        "id": "hdNCFiQq6c_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch==1.11.0+cu102  -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install DGL 0.8.1 (compatible with PyTorch 1.9.0 and CUDA 11.1)\n",
        "!pip install dgl==0.8.1 -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install sympy scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQUdfknLd7XS",
        "outputId": "b2d1199c-8bff-4bb2-f7ce-5b21eb04df92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.11.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torch-1.11.0%2Bcu102-cp310-cp310-linux_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu102) (4.12.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.13.2 requires torch>=1.13.0, but you have torch 1.11.0+cu102 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.11.0+cu102 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.11.0+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0+cu102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the dataset"
      ],
      "metadata": {
        "id": "ZSNP5TbT6oRo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrFXImF2cUN2",
        "outputId": "94e51f17-43d7-4a83-97b1-bec9279e5cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an Object defined by the authors of the paper, we are only interested in being able to use it as a wrapper for the **tfinance** dataset."
      ],
      "metadata": {
        "id": "U2GTLYVG6sJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from dgl.data import FraudYelpDataset, FraudAmazonDataset\n",
        "from dgl.data.utils import load_graphs, save_graphs\n",
        "import dgl\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, name='tfinance', homo=True, anomaly_alpha=None, anomaly_std=None):\n",
        "        self.name = name\n",
        "        graph = None\n",
        "        if name == 'tfinance':\n",
        "            graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "            graph = graph[0]\n",
        "            graph.ndata['label'] = graph.ndata['label'].argmax(1)\n",
        "\n",
        "            if anomaly_std:\n",
        "                graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "                graph = graph[0]\n",
        "                feat = graph.ndata['feature'].numpy()\n",
        "                anomaly_id = graph.ndata['label'][:,1].nonzero().squeeze(1)\n",
        "                feat = (feat-np.average(feat,0)) / np.std(feat,0)\n",
        "                feat[anomaly_id] = anomaly_std * feat[anomaly_id]\n",
        "                graph.ndata['feature'] = torch.tensor(feat)\n",
        "                graph.ndata['label'] = graph.ndata['label'].argmax(1)\n",
        "\n",
        "            if anomaly_alpha:\n",
        "                graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "                graph = graph[0]\n",
        "                feat = graph.ndata['feature'].numpy()\n",
        "                anomaly_id = list(graph.ndata['label'][:, 1].nonzero().squeeze(1))\n",
        "                normal_id = list(graph.ndata['label'][:, 0].nonzero().squeeze(1))\n",
        "                label = graph.ndata['label'].argmax(1)\n",
        "                diff = anomaly_alpha * len(label) - len(anomaly_id)\n",
        "                import random\n",
        "                new_id = random.sample(normal_id, int(diff))\n",
        "                # new_id = random.sample(anomaly_id, int(diff))\n",
        "                for idx in new_id:\n",
        "                    aid = random.choice(anomaly_id)\n",
        "                    # aid = random.choice(normal_id)\n",
        "                    feat[idx] = feat[aid]\n",
        "                    label[idx] = 1  # 0\n",
        "\n",
        "        elif name == 'tsocial':\n",
        "            graph, label_dict = load_graphs('dataset/tsocial')\n",
        "            graph = graph[0]\n",
        "\n",
        "        elif name == 'yelp':\n",
        "            dataset = FraudYelpDataset()\n",
        "            graph = dataset[0]\n",
        "            if homo:\n",
        "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
        "                graph = dgl.add_self_loop(graph)\n",
        "        elif name == 'amazon':\n",
        "            dataset = FraudAmazonDataset()\n",
        "            graph = dataset[0]\n",
        "            if homo:\n",
        "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
        "                graph = dgl.add_self_loop(graph)\n",
        "        else:\n",
        "            print('no such dataset')\n",
        "            exit(1)\n",
        "\n",
        "        graph.ndata['label'] = graph.ndata['label'].long().squeeze(-1)\n",
        "        graph.ndata['feature'] = graph.ndata['feature'].float()\n",
        "        print(graph)\n",
        "\n",
        "        self.graph = graph"
      ],
      "metadata": {
        "id": "fKWS64G_dmdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76d4a67-e9e0-4686-b683-f7bccd153836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instatiate the *Dataset* object with the **tfinance** dataset."
      ],
      "metadata": {
        "id": "8hs_G7Se7Huy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLNQt5oMdrGr",
        "outputId": "01aa8f4a-7402-44ec-8354-4b4fe5003d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=39357, num_edges=42445086,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary analysis"
      ],
      "metadata": {
        "id": "dXZdhZi77Qws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we assess what data is available.\n",
        "\n",
        "It seems that there is only Node features and not Edge features."
      ],
      "metadata": {
        "id": "_0Ueaj1P7Tm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data.graph.ndata:\n",
        "    print(\"Node features:\", data.graph.ndata.keys())\n",
        "\n",
        "# Check edge features\n",
        "if data.graph.edata:\n",
        "    print(\"Edge features:\", data.graph.edata.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh-peoef27-q",
        "outputId": "ac2e94c8-d5a2-4bff-ef58-b344d37298da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features: dict_keys(['label', 'feature'])\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GITHUB_TOKEN'] = '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'\n",
        "\n",
        "!git clone https://${GITHUB_TOKEN}@github.com/francescomazzolin/rethinking_gnn.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6oD_jII8dIJ",
        "outputId": "52bec343-42a4-4227-9f6e-f2fac3facedc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rethinking_gnn'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "Receiving objects: 100% (6/6), 5.08 KiB | 5.08 MiB/s, done.\n",
            "remote: Total 6 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing packages"
      ],
      "metadata": {
        "id": "7GBYQS6456P-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The packages specified in the paper's GitHub repository are:\n",
        "\n",
        "pytorch 1.9.0\n",
        "\n",
        "dgl 0.8.1\n",
        "\n",
        "sympy\n",
        "\n",
        "argparse\n",
        "\n",
        "scikit-learn\n",
        "\n",
        "PyTorch 1.9.0 requires an older version of Python to be installed, therefore we install Python 3.8"
      ],
      "metadata": {
        "id": "nTQRCBXq6Fxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3.8 python3.8-dev python3-pip -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeAytet_hEeg",
        "outputId": "d7a699ab-514f-4dfe-d772-47d48a61b0c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3-setuptools python3-wheel python3.8-minimal\n",
            "Suggested packages:\n",
            "  python-setuptools-doc python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3-pip python3-setuptools python3-wheel python3.8 python3.8-dev python3.8-minimal\n",
            "0 upgraded, 12 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 13.5 MB of archives.\n",
            "After this operation, 53.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.5 [1,306 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8 amd64 3.8.20-1+jammy1 [1,798 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-dev amd64 3.8.20-1+jammy1 [4,389 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-dev amd64 3.8.20-1+jammy1 [500 kB]\n",
            "Fetched 13.5 MB in 2s (5,654 kB/s)\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 123635 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../01-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../02-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../03-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../04-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8:amd64.\n",
            "Preparing to unpack .../05-libpython3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8-dev:amd64.\n",
            "Preparing to unpack .../06-libpython3.8-dev_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../07-python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../08-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../09-python3-pip_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../10-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-dev.\n",
            "Preparing to unpack .../11-python3.8-dev_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-dev (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-dev (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing PyTorch 1.9.0 gave many problems, we increased the version until there was one that did not give installation problem and allowed the script to work without hitches."
      ],
      "metadata": {
        "id": "hdNCFiQq6c_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch==1.11.0+cu102  -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install DGL 0.8.1 (compatible with PyTorch 1.9.0 and CUDA 11.1)\n",
        "!pip install dgl==0.8.1 -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install sympy scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQUdfknLd7XS",
        "outputId": "efa173fb-bb83-454e-d7d6-b5849b57c514"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.11.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torch-1.11.0%2Bcu102-cp310-cp310-linux_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m905.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu102) (4.12.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.13.2 requires torch>=1.13.0, but you have torch 1.11.0+cu102 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.11.0+cu102 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.11.0+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0+cu102\n",
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl==0.8.1\n",
            "  Downloading https://data.dgl.ai/wheels/dgl-0.8.1-cp310-cp310-manylinux1_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (2024.8.30)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.8.1\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the dataset"
      ],
      "metadata": {
        "id": "ZSNP5TbT6oRo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrFXImF2cUN2",
        "outputId": "f65377e2-18a4-4716-9774-8431361acca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an Object defined by the authors of the paper, we are only interested in being able to use it as a wrapper for the **tfinance** dataset."
      ],
      "metadata": {
        "id": "U2GTLYVG6sJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from dgl.data import FraudYelpDataset, FraudAmazonDataset\n",
        "from dgl.data.utils import load_graphs, save_graphs\n",
        "import dgl\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, name='tfinance', homo=True, anomaly_alpha=None, anomaly_std=None):\n",
        "        self.name = name\n",
        "        graph = None\n",
        "        if name == 'tfinance':\n",
        "            graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "            graph = graph[0]\n",
        "            graph.ndata['label'] = graph.ndata['label'].argmax(1)\n",
        "\n",
        "            if anomaly_std:\n",
        "                graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "                graph = graph[0]\n",
        "                feat = graph.ndata['feature'].numpy()\n",
        "                anomaly_id = graph.ndata['label'][:,1].nonzero().squeeze(1)\n",
        "                feat = (feat-np.average(feat,0)) / np.std(feat,0)\n",
        "                feat[anomaly_id] = anomaly_std * feat[anomaly_id]\n",
        "                graph.ndata['feature'] = torch.tensor(feat)\n",
        "                graph.ndata['label'] = graph.ndata['label'].argmax(1)\n",
        "\n",
        "            if anomaly_alpha:\n",
        "                graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "                graph = graph[0]\n",
        "                feat = graph.ndata['feature'].numpy()\n",
        "                anomaly_id = list(graph.ndata['label'][:, 1].nonzero().squeeze(1))\n",
        "                normal_id = list(graph.ndata['label'][:, 0].nonzero().squeeze(1))\n",
        "                label = graph.ndata['label'].argmax(1)\n",
        "                diff = anomaly_alpha * len(label) - len(anomaly_id)\n",
        "                import random\n",
        "                new_id = random.sample(normal_id, int(diff))\n",
        "                # new_id = random.sample(anomaly_id, int(diff))\n",
        "                for idx in new_id:\n",
        "                    aid = random.choice(anomaly_id)\n",
        "                    # aid = random.choice(normal_id)\n",
        "                    feat[idx] = feat[aid]\n",
        "                    label[idx] = 1  # 0\n",
        "\n",
        "        elif name == 'tsocial':\n",
        "            graph, label_dict = load_graphs('dataset/tsocial')\n",
        "            graph = graph[0]\n",
        "\n",
        "        elif name == 'yelp':\n",
        "            dataset = FraudYelpDataset()\n",
        "            graph = dataset[0]\n",
        "            if homo:\n",
        "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
        "                graph = dgl.add_self_loop(graph)\n",
        "        elif name == 'amazon':\n",
        "            dataset = FraudAmazonDataset()\n",
        "            graph = dataset[0]\n",
        "            if homo:\n",
        "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
        "                graph = dgl.add_self_loop(graph)\n",
        "        else:\n",
        "            print('no such dataset')\n",
        "            exit(1)\n",
        "\n",
        "        graph.ndata['label'] = graph.ndata['label'].long().squeeze(-1)\n",
        "        graph.ndata['feature'] = graph.ndata['feature'].float()\n",
        "        print(graph)\n",
        "\n",
        "        self.graph = graph"
      ],
      "metadata": {
        "id": "fKWS64G_dmdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83df890-8d10-4543-8e7c-617d5a1e793e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instatiate the *Dataset* object with the **tfinance** dataset."
      ],
      "metadata": {
        "id": "8hs_G7Se7Huy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLNQt5oMdrGr",
        "outputId": "e9c20c68-6904-41db-f33a-959504db2038"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=39357, num_edges=42445086,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary analysis"
      ],
      "metadata": {
        "id": "dXZdhZi77Qws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we assess what data is available."
      ],
      "metadata": {
        "id": "_0Ueaj1P7Tm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data.graph.ndata:\n",
        "    print(\"Node features:\", data.graph.ndata.keys())\n",
        "\n",
        "# Check edge features\n",
        "if data.graph.edata:\n",
        "    print(\"Edge features:\", data.graph.edata.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh-peoef27-q",
        "outputId": "1d7fe6c3-31c5-4403-d43c-9feeccc9cae7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features: dict_keys(['label', 'feature'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that there is **only Node features** and not Edge features."
      ],
      "metadata": {
        "id": "gVFW78Ov_KLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( data.graph.ndata['feature'])"
      ],
      "metadata": {
        "id": "FvLRldlw_N4g",
        "outputId": "1325f2d7-3a95-499d-ba7f-a10f2be6cae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.5500e+02, 6.2100e+02, 5.7000e+01,  ..., 8.2000e+01, 8.7387e-01,\n",
            "         8.5946e-01],\n",
            "        [1.5580e+03, 4.8480e+03, 8.4000e+01,  ..., 2.0200e+02, 1.8333e-01,\n",
            "         4.4231e-02],\n",
            "        [8.9800e+02, 6.8900e+02, 2.0000e+00,  ..., 5.0000e+01, 2.5390e-01,\n",
            "         2.2383e-01],\n",
            "        ...,\n",
            "        [1.2000e+01, 4.4600e+02, 1.0000e+00,  ..., 1.0000e+00, 5.8333e-01,\n",
            "         5.8333e-01],\n",
            "        [1.3000e+01, 9.2500e+02, 1.1000e+01,  ..., 2.5000e+01, 3.0769e-01,\n",
            "         1.5385e-01],\n",
            "        [1.4000e+01, 8.8200e+02, 1.3000e+01,  ..., 2.8000e+01, 2.8571e-01,\n",
            "         1.4286e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = data.graph.ndata['feature'][0]\n",
        "print(\"The first node has the following features\", example)\n",
        "print(f\"\\nThey are: {len(example)}\")\n"
      ],
      "metadata": {
        "id": "_Jdt6qHB_1Jr",
        "outputId": "782734a8-f6f1-4da1-9814-effc27f2c8e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first node has the following features tensor([555.0000, 621.0000,  57.0000,  16.0000, 376.0000,  90.0000,  28.0000,\n",
            "         82.0000,   0.8739,   0.8595])\n",
            "\n",
            "They are: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = list(data.graph.ndata.keys())\n",
        "\n",
        "print(\"The node feature attributes are:\", attributes)"
      ],
      "metadata": {
        "id": "rUA4cayGBCjh",
        "outputId": "0ff9b7af-39ba-494c-c0ed-92c4d5bf2c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The node feature attributes are: ['label', 'feature']\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GITHUB_TOKEN'] = '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'\n",
        "\n",
        "!git clone https://${GITHUB_TOKEN}@github.com/francescomazzolin/rethinking_gnn.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6oD_jII8dIJ",
        "outputId": "67909646-7f29-4028-d1fb-d5e918c217e1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'rethinking_gnn' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing packages"
      ],
      "metadata": {
        "id": "7GBYQS6456P-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The packages specified in the paper's GitHub repository are:\n",
        "\n",
        "pytorch 1.9.0\n",
        "\n",
        "dgl 0.8.1\n",
        "\n",
        "sympy\n",
        "\n",
        "argparse\n",
        "\n",
        "scikit-learn\n",
        "\n",
        "PyTorch 1.9.0 requires an older version of Python to be installed, therefore we install Python 3.8"
      ],
      "metadata": {
        "id": "nTQRCBXq6Fxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3.8 python3.8-dev python3-pip -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeAytet_hEeg",
        "outputId": "d7a699ab-514f-4dfe-d772-47d48a61b0c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3-setuptools python3-wheel python3.8-minimal\n",
            "Suggested packages:\n",
            "  python-setuptools-doc python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8 libpython3.8-dev libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3-pip python3-setuptools python3-wheel python3.8 python3.8-dev python3.8-minimal\n",
            "0 upgraded, 12 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 13.5 MB of archives.\n",
            "After this operation, 53.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.5 [1,306 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8 amd64 3.8.20-1+jammy1 [1,798 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-dev amd64 3.8.20-1+jammy1 [4,389 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-dev amd64 3.8.20-1+jammy1 [500 kB]\n",
            "Fetched 13.5 MB in 2s (5,654 kB/s)\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 123635 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../01-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../02-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../03-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../04-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8:amd64.\n",
            "Preparing to unpack .../05-libpython3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8-dev:amd64.\n",
            "Preparing to unpack .../06-libpython3.8-dev_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../07-python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../08-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../09-python3-pip_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../10-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-dev.\n",
            "Preparing to unpack .../11-python3.8-dev_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-dev (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-dev:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-dev (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing PyTorch 1.9.0 gave many problems, we increased the version until there was one that did not give installation problem and allowed the script to work without hitches."
      ],
      "metadata": {
        "id": "hdNCFiQq6c_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch==1.11.0+cu102  -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Install DGL 0.8.1 (compatible with PyTorch 1.9.0 and CUDA 11.1)\n",
        "!pip install dgl==0.8.1 -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install sympy scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQUdfknLd7XS",
        "outputId": "efa173fb-bb83-454e-d7d6-b5849b57c514"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.11.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torch-1.11.0%2Bcu102-cp310-cp310-linux_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m905.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu102) (4.12.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.13.2 requires torch>=1.13.0, but you have torch 1.11.0+cu102 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.11.0+cu102 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.11.0+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0+cu102\n",
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl==0.8.1\n",
            "  Downloading https://data.dgl.ai/wheels/dgl-0.8.1-cp310-cp310-manylinux1_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==0.8.1) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.8.1) (2024.8.30)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.8.1\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the dataset"
      ],
      "metadata": {
        "id": "ZSNP5TbT6oRo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrFXImF2cUN2",
        "outputId": "f65377e2-18a4-4716-9774-8431361acca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an Object defined by the authors of the paper, we are only interested in being able to use it as a wrapper for the **tfinance** dataset."
      ],
      "metadata": {
        "id": "U2GTLYVG6sJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from dgl.data import FraudYelpDataset, FraudAmazonDataset\n",
        "from dgl.data.utils import load_graphs, save_graphs\n",
        "import dgl\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, name='tfinance', homo=True, anomaly_alpha=None, anomaly_std=None):\n",
        "        self.name = name\n",
        "        graph = None\n",
        "        if name == 'tfinance':\n",
        "            graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "            graph = graph[0]\n",
        "            graph.ndata['label'] = graph.ndata['label'].argmax(1)\n",
        "\n",
        "            if anomaly_std:\n",
        "                graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "                graph = graph[0]\n",
        "                feat = graph.ndata['feature'].numpy()\n",
        "                anomaly_id = graph.ndata['label'][:,1].nonzero().squeeze(1)\n",
        "                feat = (feat-np.average(feat,0)) / np.std(feat,0)\n",
        "                feat[anomaly_id] = anomaly_std * feat[anomaly_id]\n",
        "                graph.ndata['feature'] = torch.tensor(feat)\n",
        "                graph.ndata['label'] = graph.ndata['label'].argmax(1)\n",
        "\n",
        "            if anomaly_alpha:\n",
        "                graph, label_dict = load_graphs('/content/drive/My Drive/tfinance')\n",
        "                graph = graph[0]\n",
        "                feat = graph.ndata['feature'].numpy()\n",
        "                anomaly_id = list(graph.ndata['label'][:, 1].nonzero().squeeze(1))\n",
        "                normal_id = list(graph.ndata['label'][:, 0].nonzero().squeeze(1))\n",
        "                label = graph.ndata['label'].argmax(1)\n",
        "                diff = anomaly_alpha * len(label) - len(anomaly_id)\n",
        "                import random\n",
        "                new_id = random.sample(normal_id, int(diff))\n",
        "                # new_id = random.sample(anomaly_id, int(diff))\n",
        "                for idx in new_id:\n",
        "                    aid = random.choice(anomaly_id)\n",
        "                    # aid = random.choice(normal_id)\n",
        "                    feat[idx] = feat[aid]\n",
        "                    label[idx] = 1  # 0\n",
        "\n",
        "        elif name == 'tsocial':\n",
        "            graph, label_dict = load_graphs('dataset/tsocial')\n",
        "            graph = graph[0]\n",
        "\n",
        "        elif name == 'yelp':\n",
        "            dataset = FraudYelpDataset()\n",
        "            graph = dataset[0]\n",
        "            if homo:\n",
        "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
        "                graph = dgl.add_self_loop(graph)\n",
        "        elif name == 'amazon':\n",
        "            dataset = FraudAmazonDataset()\n",
        "            graph = dataset[0]\n",
        "            if homo:\n",
        "                graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
        "                graph = dgl.add_self_loop(graph)\n",
        "        else:\n",
        "            print('no such dataset')\n",
        "            exit(1)\n",
        "\n",
        "        graph.ndata['label'] = graph.ndata['label'].long().squeeze(-1)\n",
        "        graph.ndata['feature'] = graph.ndata['feature'].float()\n",
        "        print(graph)\n",
        "\n",
        "        self.graph = graph"
      ],
      "metadata": {
        "id": "fKWS64G_dmdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83df890-8d10-4543-8e7c-617d5a1e793e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instatiate the *Dataset* object with the **tfinance** dataset."
      ],
      "metadata": {
        "id": "8hs_G7Se7Huy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLNQt5oMdrGr",
        "outputId": "e9c20c68-6904-41db-f33a-959504db2038"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=39357, num_edges=42445086,\n",
            "      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feature': Scheme(shape=(10,), dtype=torch.float32)}\n",
            "      edata_schemes={})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary analysis"
      ],
      "metadata": {
        "id": "dXZdhZi77Qws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we assess what data is available."
      ],
      "metadata": {
        "id": "_0Ueaj1P7Tm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data.graph.ndata:\n",
        "    print(\"Node features:\", data.graph.ndata.keys())\n",
        "\n",
        "# Check edge features\n",
        "if data.graph.edata:\n",
        "    print(\"Edge features:\", data.graph.edata.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh-peoef27-q",
        "outputId": "1d7fe6c3-31c5-4403-d43c-9feeccc9cae7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features: dict_keys(['label', 'feature'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that there is **only Node features** and not Edge features."
      ],
      "metadata": {
        "id": "gVFW78Ov_KLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( data.graph.ndata['feature'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvLRldlw_N4g",
        "outputId": "1325f2d7-3a95-499d-ba7f-a10f2be6cae3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.5500e+02, 6.2100e+02, 5.7000e+01,  ..., 8.2000e+01, 8.7387e-01,\n",
            "         8.5946e-01],\n",
            "        [1.5580e+03, 4.8480e+03, 8.4000e+01,  ..., 2.0200e+02, 1.8333e-01,\n",
            "         4.4231e-02],\n",
            "        [8.9800e+02, 6.8900e+02, 2.0000e+00,  ..., 5.0000e+01, 2.5390e-01,\n",
            "         2.2383e-01],\n",
            "        ...,\n",
            "        [1.2000e+01, 4.4600e+02, 1.0000e+00,  ..., 1.0000e+00, 5.8333e-01,\n",
            "         5.8333e-01],\n",
            "        [1.3000e+01, 9.2500e+02, 1.1000e+01,  ..., 2.5000e+01, 3.0769e-01,\n",
            "         1.5385e-01],\n",
            "        [1.4000e+01, 8.8200e+02, 1.3000e+01,  ..., 2.8000e+01, 2.8571e-01,\n",
            "         1.4286e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = data.graph.ndata['feature'][0]\n",
        "print(\"The first node has the following features\", example)\n",
        "print(f\"\\nThey are: {len(example)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jdt6qHB_1Jr",
        "outputId": "782734a8-f6f1-4da1-9814-effc27f2c8e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first node has the following features tensor([555.0000, 621.0000,  57.0000,  16.0000, 376.0000,  90.0000,  28.0000,\n",
            "         82.0000,   0.8739,   0.8595])\n",
            "\n",
            "They are: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = dir(example)\n",
        "print(attributes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUA4cayGBCjh",
        "outputId": "5c1a2631-82ae-4c50-cb6c-2c53d42643ad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H', 'T', '__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__dlpack__', '__dlpack_device__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ifloordiv__', '__ilshift__', '__imod__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rlshift__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__torch_function__', '__truediv__', '__weakref__', '__xor__', '_autocast_to_full_precision', '_autocast_to_reduced_precision', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_conj', '_conj_physical', '_dimI', '_dimV', '_fix_weakref', '_grad', '_grad_fn', '_indices', '_is_view', '_is_zerotensor', '_make_subclass', '_make_wrapper_subclass', '_neg_view', '_nnz', '_python_dispatch', '_reduce_ex_internal', '_storage', '_update_names', '_values', '_version', 'abs', 'abs_', 'absolute', 'absolute_', 'acos', 'acos_', 'acosh', 'acosh_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'adjoint', 'align_as', 'align_to', 'all', 'allclose', 'amax', 'amin', 'aminmax', 'angle', 'any', 'apply_', 'arccos', 'arccos_', 'arccosh', 'arccosh_', 'arcsin', 'arcsin_', 'arcsinh', 'arcsinh_', 'arctan', 'arctan2', 'arctan2_', 'arctan_', 'arctanh', 'arctanh_', 'argmax', 'argmin', 'argsort', 'argwhere', 'as_strided', 'as_strided_', 'as_subclass', 'asin', 'asin_', 'asinh', 'asinh_', 'atan', 'atan2', 'atan2_', 'atan_', 'atanh', 'atanh_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bfloat16', 'bincount', 'bitwise_and', 'bitwise_and_', 'bitwise_left_shift', 'bitwise_left_shift_', 'bitwise_not', 'bitwise_not_', 'bitwise_or', 'bitwise_or_', 'bitwise_right_shift', 'bitwise_right_shift_', 'bitwise_xor', 'bitwise_xor_', 'bmm', 'bool', 'broadcast_to', 'byte', 'cauchy_', 'cdouble', 'ceil', 'ceil_', 'cfloat', 'char', 'cholesky', 'cholesky_inverse', 'cholesky_solve', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clip', 'clip_', 'clone', 'coalesce', 'col_indices', 'conj', 'conj_physical', 'conj_physical_', 'contiguous', 'copy_', 'copysign', 'copysign_', 'corrcoef', 'cos', 'cos_', 'cosh', 'cosh_', 'count_nonzero', 'cov', 'cpu', 'cross', 'crow_indices', 'cuda', 'cummax', 'cummin', 'cumprod', 'cumprod_', 'cumsum', 'cumsum_', 'data', 'data_ptr', 'deg2rad', 'deg2rad_', 'dense_dim', 'dequantize', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'diagonal_scatter', 'diff', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'divide', 'divide_', 'dot', 'double', 'dsplit', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp2', 'exp2_', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fill_', 'fill_diagonal_', 'fix', 'fix_', 'flatten', 'flip', 'fliplr', 'flipud', 'float', 'float_power', 'float_power_', 'floor', 'floor_', 'floor_divide', 'floor_divide_', 'fmax', 'fmin', 'fmod', 'fmod_', 'frac', 'frac_', 'frexp', 'gather', 'gcd', 'gcd_', 'ge', 'ge_', 'geometric_', 'geqrf', 'ger', 'get_device', 'grad', 'grad_fn', 'greater', 'greater_', 'greater_equal', 'greater_equal_', 'gt', 'gt_', 'half', 'hardshrink', 'has_names', 'heaviside', 'heaviside_', 'histc', 'histogram', 'hsplit', 'hypot', 'hypot_', 'i0', 'i0_', 'igamma', 'igamma_', 'igammac', 'igammac_', 'imag', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'inner', 'int', 'int_repr', 'inverse', 'is_coalesced', 'is_complex', 'is_conj', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_inference', 'is_leaf', 'is_meta', 'is_mkldnn', 'is_mlc', 'is_neg', 'is_nonzero', 'is_ort', 'is_pinned', 'is_quantized', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'is_sparse_csr', 'is_vulkan', 'is_xpu', 'isclose', 'isfinite', 'isinf', 'isnan', 'isneginf', 'isposinf', 'isreal', 'istft', 'item', 'kron', 'kthvalue', 'layout', 'lcm', 'lcm_', 'ldexp', 'ldexp_', 'le', 'le_', 'lerp', 'lerp_', 'less', 'less_', 'less_equal', 'less_equal_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logaddexp', 'logaddexp2', 'logcumsumexp', 'logdet', 'logical_and', 'logical_and_', 'logical_not', 'logical_not_', 'logical_or', 'logical_or_', 'logical_xor', 'logical_xor_', 'logit', 'logit_', 'logsumexp', 'long', 'lstsq', 'lt', 'lt_', 'lu', 'lu_solve', 'mH', 'mT', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_exp', 'matrix_power', 'max', 'maximum', 'mean', 'median', 'min', 'minimum', 'mm', 'mode', 'moveaxis', 'movedim', 'msort', 'mul', 'mul_', 'multinomial', 'multiply', 'multiply_', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'names', 'nan_to_num', 'nan_to_num_', 'nanmean', 'nanmedian', 'nanquantile', 'nansum', 'narrow', 'narrow_copy', 'ndim', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'negative', 'negative_', 'nelement', 'new', 'new_empty', 'new_empty_strided', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nextafter', 'nextafter_', 'nonzero', 'norm', 'normal_', 'not_equal', 'not_equal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'outer', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'positive', 'pow', 'pow_', 'prelu', 'prod', 'put', 'put_', 'q_per_channel_axis', 'q_per_channel_scales', 'q_per_channel_zero_points', 'q_scale', 'q_zero_point', 'qr', 'qscheme', 'quantile', 'rad2deg', 'rad2deg_', 'random_', 'ravel', 'real', 'reciprocal', 'reciprocal_', 'record_stream', 'refine_names', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'rename', 'rename_', 'renorm', 'renorm_', 'repeat', 'repeat_interleave', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'resolve_conj', 'resolve_neg', 'retain_grad', 'retains_grad', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'scatter_reduce', 'select', 'select_scatter', 'set_', 'sgn', 'sgn_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'signbit', 'sin', 'sin_', 'sinc', 'sinc_', 'sinh', 'sinh_', 'size', 'slice_scatter', 'slogdet', 'smm', 'softmax', 'solve', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'square', 'square_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'subtract', 'subtract_', 'sum', 'sum_to_size', 'svd', 'swapaxes', 'swapaxes_', 'swapdims', 'swapdims_', 'symeig', 't', 't_', 'take', 'take_along_dim', 'tan', 'tan_', 'tanh', 'tanh_', 'tensor_split', 'tile', 'to', 'to_dense', 'to_mkldnn', 'to_sparse', 'to_sparse_coo', 'to_sparse_csr', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'triangular_solve', 'tril', 'tril_', 'triu', 'triu_', 'true_divide', 'true_divide_', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unflatten', 'unfold', 'uniform_', 'unique', 'unique_consecutive', 'unsafe_chunk', 'unsafe_split', 'unsafe_split_with_sizes', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'vdot', 'view', 'view_as', 'vsplit', 'where', 'xlogy', 'xlogy_', 'xpu', 'zero_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example.names"
      ],
      "metadata": {
        "id": "aJcQrcnVFl6G",
        "outputId": "864b8fa1-1329-4624-a665-54a11cdfa92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}